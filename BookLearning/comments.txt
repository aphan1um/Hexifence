Andy Phan (aphan1)
Martin Cheong (cheongm)

Our implementation consists of several components. 

- The aphan1 class corresponds to our AI that implements the Player interface. 
- The state of the game is represented by instances of Board, which consists of various methods including functions 
that check for board symmetry (which are used for space reduction).
- The Chain and ChainFinder classes are used to find chains on the board (which are used by the Preprocessor class
to determine optimal play).
- The GradientLearn and LearningTest classes were used to implement gradient descent learning to determine a set of 
weights for the evaluation function that is used by our agent.
- The TranspositionTable and ZobristHasher classes are used to store board states and their corresponding backed-up 
minimax values to reduce duplicate work when running the minimax algorithm.

Our approach to the project was to use the minimax algorithm (depth-first search) alongside Alpha-Beta pruning
for our agent to decide which move to make. The evaluation function was generated by performing gradient descent
learning based on the following features:

- The score margin of the game.
- The length of the longest chain.

Alongside this, we used a transposition table that used Zobrist hashing to store states and their backed-up minimax
values to reduce the amount of work needed to be done when searching the tree.

Furthermore, we made a few observations about the game that helped us in developing our agent. The game allows
for what's known as a "double-cross strategy" that can force the opponent to make a move for the agent's gain.
// ADD MORE STUFF HERE //